{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrZK24uCsiUT"
      },
      "source": [
        "# Dataset Size Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Link to ReadMe Section:\n",
        "https://gitlab.cs.vt.edu/sdeepti/facial-expression-recognition/-/blob/main/README.md#experimenting-different-dataset-sizes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Citations:\n",
        "- https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "c\n",
        "Perform a sensitivity analysis to quantify the relationship between dataset size and model performance. We want to take fractions of the orginial dataset and observe how the model's ability to classify accurately changes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njRPLGF7wHTB"
      },
      "source": [
        "#### 1. Initial Set-Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This adds all the imports that are necessary for the code to run smoothly. It involves importing `torch` which is necessary to work with our model and retrieve our datasets. Additionally, `sklearn` is used for evaluation metrics to be reported."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset being used for this experiment is the **KDEF Dataset** which can be found by clicking the following link:\n",
        "https://www.kdef.se/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhvatYpRa9yu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import copy\n",
        "import csv\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "import torch\n",
        "from torchvision import transforms, models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# For metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIrRt7UVj8K8"
      },
      "source": [
        "This sets up some of the constant parameters necessary throughout the code. The data split is set up for the experiment testing with 10% of the original dataset. It will train the model with 10% of the dataset, then validate with another 10% of the data and finally, test with the remaining 80% of the KDEF dataset.\n",
        "\n",
        "This specific data directory sets up the experiment to test with 10% of the dataset, however, the various dataset size experiments can be conducted by changing the directory to the following:\n",
        "- `data_dir = '../data/face_images_10_10_80'` - for 10% train, 10% validation, 80% test\n",
        "- `data_dir = '../data/face_images_20_10_70'` - for 20% train, 10% validation, 70% test\n",
        "- `data_dir = '../data/face_images_50_10_40'` - for 50% train, 10% validation, 40% test\n",
        "- `data_dir = '../data/face_images_70_10_20'` - for 70% train, 10% validation, 20% test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAzT3x2bbPgB",
        "outputId": "a3870200-58b1-4418-ab49-33dd082d1f5c"
      },
      "outputs": [],
      "source": [
        "# use 80/10/10 train val test split\n",
        "data_dir = '../data/face_images_10_10_80' #change directory as per dataset size\n",
        "print(f'using {data_dir} as data folder')\n",
        "\n",
        "model_save_path = 'FEC_resnet50_trained.pt'\n",
        "\n",
        "num_classes = 7\n",
        "\n",
        "# print if running on gpu or on cpu\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')\n",
        "\n",
        "# flag for feature extracting, when true, finetune the entire model\n",
        "# when false, only update reshaped layer parameters (last fully connected layer)\n",
        "finetune_all_parmas = True\n",
        "\n",
        "# expected input size for resnet\n",
        "input_size = 224"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6ru1rz0l6YK"
      },
      "source": [
        "#### 2. Perform Image Pre-Processing and Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This performs the desired pre-processing and data augmentation steps. It splits the necessary transformations based on whether the image is used for training, validation or testing. \n",
        "\n",
        "The training images are resized, having arbitrary rotations added and random horizontal flips. They are also altered by varying their brightness, contrast and saturation values. They are lastly normalizd as per the ImageNet standard.\n",
        "\n",
        "The validation and testing images are only resized and normalized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGHbZlBVcaLt"
      },
      "outputs": [],
      "source": [
        "# transformations to apply to images\n",
        "# data augmentation and normalization for training\n",
        "# just normalization for validation and testing\n",
        "# https://pytorch.org/vision/stable/transforms.html\n",
        "data_transforms = {\n",
        "\t'train': transforms.Compose([\n",
        "\t\ttransforms.Resize(size=(input_size, input_size)),\n",
        "\t\t# transforms.Grayscale(), (cannot use greyscale with resnet)\n",
        "\t\t# rotation augmentation\n",
        "\t\ttransforms.RandomRotation(10),\n",
        "\t\t# random flip augmentaion\n",
        "\t\ttransforms.RandomHorizontalFlip(),\n",
        "\t\t# jitter brightness, contrast, saturation augmentaion\n",
        "\t\ttransforms.ColorJitter(brightness=0.2, contrast=0.1, saturation=0.1, hue=0),\n",
        "\t\t# convert to tensor and normalize\n",
        "\t\ttransforms.ToTensor(),\n",
        "\t\t# use ImageNet standard mean and std dev for transfer learning\n",
        "\t\ttransforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "\t]),\n",
        "\t'val': transforms.Compose([\n",
        "\t\ttransforms.Resize(size=(input_size, input_size)),\n",
        "\t\ttransforms.ToTensor(),\n",
        "\t\t# use ImageNet standard mean and std dev for transfer learning\n",
        "\t\ttransforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "\t]),\n",
        "\t'test': transforms.Compose([\n",
        "\t\ttransforms.Resize(size=(input_size, input_size)),\n",
        "\t\ttransforms.ToTensor(),\n",
        "\t\t# use ImageNet standard mean and std dev for transfer learning\n",
        "\t\ttransforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "\t])\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoGmsyNixP5f"
      },
      "source": [
        "#### 3. Create Training/Validation Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following code sets the batch size and creates the training, validation and testing datasets. It then performs the respective transformations on the images of each dataset and creates data loaders for each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oR30YDM4xcfj"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "\n",
        "# create train and validation datasets and apply transforms\n",
        "datasets_dict = {dataset_type: ImageFolder(os.path.join(data_dir, dataset_type),\n",
        "\ttransform=data_transforms[dataset_type]) for dataset_type in ['train', 'val', 'test']}\n",
        "\n",
        "# create train and validation dataloaders\n",
        "dataloaders_dict = {dataset_type: DataLoader(datasets_dict[dataset_type], batch_size=batch_size, shuffle=True) for dataset_type in ['train', 'val', 'test']}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X18d3MukxpNz"
      },
      "source": [
        "#### 4. Funcion to Initialize Our Pretrained ResNet Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The function below sets the parameters for the model. This experiment will be using the original ResNet50 Model specifically. It also sets up the prints for the information about the model such as the total number of parameters, number of trainable parameters etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eq8mE66Vxufn"
      },
      "outputs": [],
      "source": [
        "# initialize a pretrained resnet model\n",
        "def init_model(num_classes, resnet_size, finetune_all_parmas,\n",
        "\t\t\t\tprint_model=True, class_to_idx=None):\n",
        "\n",
        "\tmodel = None\n",
        "\n",
        "\tif resnet_size == 18:\n",
        "\t\tmodel = models.resnet18(pretrained=True)\n",
        "\telif resnet_size == 34:\n",
        "\t\tmodel = models.resnet34(pretrained=True)\n",
        "\telif resnet_size == 50:\n",
        "\t\tmodel = models.resnet50(pretrained=True)\n",
        "\telif resnet_size == 101:\n",
        "\t\tmodel = models.resnet101(pretrained=True)\n",
        "\telif resnet_size == 152:\n",
        "\t\tmodel = models.resnet152(pretrained=True)\n",
        "\telse:\n",
        "\t\traise ValueError(f'Invalid size of {resnet_size} given for resnet size.')\n",
        "\n",
        "\n",
        "\t# sets requires_grad attribute of parameters in model to false if not finetuning all parameters\n",
        "\tif not finetune_all_parmas:\n",
        "\t\t# don't relearn weights when transfer learning\n",
        "\t\tfor param in model.parameters():\n",
        "\t\t\tparam.requires_grad = False\n",
        "\n",
        "\t# when transfer learning, set last layer to be fully connected with num_classes number of outputs\n",
        "\tmodel.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "\t# map classes to indexes\n",
        "\tif class_to_idx:\n",
        "\t\tmodel.class_to_idx = class_to_idx\n",
        "\t\tmodel.idx_to_class = {idx: class_ for class_, idx in model.class_to_idx.items()}\n",
        "\n",
        "\n",
        "\t# print model information\n",
        "\tif print_model:\n",
        "\t\t# print model summary\n",
        "\t\tprint()\n",
        "\t\tprint(f'Using resnet size: {resnet_size}')\n",
        "\t\tprint('Model summary:')\n",
        "\t\tprint(model)\n",
        "\n",
        "\t\t# print model parameters\n",
        "\t\ttotal_params = sum(p.numel() for p in model.parameters())\n",
        "\t\ttrainable_names = [name for name, p in model.named_parameters() if p.requires_grad]\n",
        "\t\ttotal_trainable_params = len(trainable_names)\n",
        "\t\tprint()\n",
        "\t\tprint(f'Model parameters ({total_params} total, {total_trainable_params} trainable)')\n",
        "\t\tprint('List of trainable parameters:')\n",
        "\t\tpprint(trainable_names, width=80, compact=True)\n",
        "\t\tprint()\n",
        "\n",
        "\t\t# print mapping for class indicies\n",
        "\t\tif class_to_idx:\n",
        "\t\t\tprint('Model index to class mappings:')\n",
        "\t\t\tprint(model.idx_to_class)\n",
        "\t\t\tprint()\n",
        "\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTrosEhSx-3l"
      },
      "source": [
        "#### 5. Function to Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The function below performs the training for the model by taking in the model, a dictionary of dataloaders, a loss function, an optimizer, and a specified number of epochs to train and validate for. It saves the train and validation loss and accuracy history for each of the epochs and writes it to a csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXU_5I5PyENz"
      },
      "outputs": [],
      "source": [
        "# model training and validation\n",
        "def train(model, dataloaders, criterion, optimizer,\n",
        "\t\t\tnum_epochs=25, save_path=None, save_history_to_csv=True):\n",
        "\n",
        "\tsince = time.time()\n",
        "\n",
        "\t# save train and val loss/accuracy history for each epoch\n",
        "\ttrain_loss_history = []\n",
        "\tval_loss_history = []\n",
        "\ttrain_acc_history = []\n",
        "\tval_acc_history = []\n",
        "\n",
        "\n",
        "\tbest_model_wts = copy.deepcopy(model.state_dict())\n",
        "\tbest_acc = 0.0\n",
        "\n",
        "\tfor epoch in range(num_epochs):\n",
        "\t\tprint(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "\t\tprint('-' * 10)\n",
        "\n",
        "\t\t# Each epoch has a training and validation phase\n",
        "\t\tfor phase in ['train', 'val']:\n",
        "\t\t\tif phase == 'train':\n",
        "\t\t\t\tmodel.train()  # Set model to training mode\n",
        "\t\t\telse:\n",
        "\t\t\t\tmodel.eval()   # Set model to evaluate mode\n",
        "\n",
        "\t\t\trunning_loss = 0.0\n",
        "\t\t\trunning_corrects = 0\n",
        "\n",
        "\t\t\t# Iterate over data.\n",
        "\t\t\tfor inputs, labels in dataloaders[phase]:\n",
        "\t\t\t\tinputs = inputs.to(device)\n",
        "\t\t\t\tlabels = labels.to(device)\n",
        "\n",
        "\t\t\t\t# zero the parameter gradients\n",
        "\t\t\t\toptimizer.zero_grad()\n",
        "\n",
        "\t\t\t\t# forward\n",
        "\t\t\t\t# track history if only in train\n",
        "\t\t\t\twith torch.set_grad_enabled(phase == 'train'):\n",
        "\t\t\t\t\t# Get model outputs and calculate loss\n",
        "\t\t\t\t\toutputs = model(inputs)\n",
        "\t\t\t\t\tloss = criterion(outputs, labels)\n",
        "\n",
        "\t\t\t\t\t_, preds = torch.max(outputs, 1)\n",
        "\n",
        "\t\t\t\t\t# backward + optimize only if in training phase\n",
        "\t\t\t\t\tif phase == 'train':\n",
        "\t\t\t\t\t\tloss.backward()\n",
        "\t\t\t\t\t\toptimizer.step()\n",
        "\n",
        "\t\t\t\t# statistics\n",
        "\t\t\t\trunning_loss += loss.item() * inputs.size(0)\n",
        "\t\t\t\trunning_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "\t\t\tepoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "\t\t\tepoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "\t\t\tprint(f'{phase} loss: {epoch_loss:.4f} acc: {epoch_acc:.4f}')\n",
        "\n",
        "\t\t\t# deep copy the model if best accuracy\n",
        "\t\t\tif phase == 'val' and epoch_acc > best_acc:\n",
        "\t\t\t\tbest_acc = epoch_acc\n",
        "\t\t\t\tbest_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "\t\t\t# save loss and accuracy to history\n",
        "\t\t\tif phase == 'train':\n",
        "\t\t\t\ttrain_loss_history.append(epoch_loss)\n",
        "\t\t\t\ttrain_acc_history.append(epoch_acc.item())\n",
        "\t\t\telif phase == 'val':\n",
        "\t\t\t\tval_loss_history.append(epoch_loss)\n",
        "\t\t\t\tval_acc_history.append(epoch_acc.item())\n",
        "\n",
        "\t\tprint()\n",
        "\n",
        "\ttime_elapsed = time.time() - since\n",
        "\tprint(f'Training complete in {(time_elapsed // 60):.0f}m {(time_elapsed % 60):.0f}s')\n",
        "\tprint(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "\t# load best model weights\n",
        "\tmodel.load_state_dict(best_model_wts)\n",
        "\n",
        "\t# write history csv file\n",
        "\tif save_history_to_csv:\n",
        "\t\thistory_header = ['train_loss', 'val_loss', 'train_acc', 'val_acc']\n",
        "\t\thistory_filename = model_save_path.split('.')[0] + '_history.csv'\n",
        "\t\thistory = zip(train_loss_history, val_loss_history, train_acc_history, val_acc_history)\n",
        "\t\thistory = [list(row) for row in history]\n",
        "\t\twith open(history_filename, 'w') as csv_file:\n",
        "\t\t\twriter = csv.writer(csv_file)\n",
        "\t\t\twriter.writerow(history_header)\n",
        "\t\t\tfor row in history:\n",
        "\t\t\t\twriter.writerow(row)\n",
        "\n",
        "\t\t# save trained model to disk\n",
        "\t\tif save_path:\n",
        "\t\t\ttorch.save(model.state_dict(), save_path)\n",
        "\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMTaT4FYyMEn"
      },
      "source": [
        "#### 6. Function to Test the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following code creates the function used to test the model on the testing set. It evaluates the model's performance and computes metrics that are later used for analysis, such as the accuracy, F1 Score and confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97V8hC_ByOFy"
      },
      "outputs": [],
      "source": [
        "# tests performance on test set and computes metrics\n",
        "def test(model, test_loader):\n",
        "\t# list of predicted labels of all batches\n",
        "\tpredicted_labels = torch.zeros(0, dtype=torch.long, device='cpu')\n",
        "\t# list of actual labels of all batches\n",
        "\tactual_labels = torch.zeros(0, dtype=torch.long, device='cpu')\n",
        "\n",
        "\twith torch.no_grad():\n",
        "\t\tmodel.eval()\n",
        "\t\t# get batch of inputs (image) and outputs (expression label) from test_loader\n",
        "\t\tfor inputs, labels in test_loader:\n",
        "\t\t\tinputs = inputs.to(device)\n",
        "\t\t\tlabels = labels.to(device)\n",
        "\n",
        "\t\t\t# use model to predict label\n",
        "\t\t\toutputs = model(inputs)\n",
        "\t\t\t_, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "\t\t\t# append batch prediction labels and actual labels\n",
        "\t\t\tpredicted_labels = torch.cat([predicted_labels, preds.view(-1).cpu()])\n",
        "\t\t\tactual_labels = torch.cat([actual_labels, labels.view(-1).cpu()])\n",
        "\n",
        "\tprint('\\nTest Metrics:')\n",
        "\t# print confusion matrix\n",
        "\tprint('Confusion Matrix:')\n",
        "\tprint(confusion_matrix(actual_labels.numpy(), predicted_labels.numpy()))\n",
        "\n",
        "\tprint('Test Accuracy:', accuracy_score(actual_labels.numpy(), predicted_labels.numpy()))\n",
        "\tprint('F1 score:', f1_score(actual_labels.numpy(), predicted_labels.numpy(), average='weighted'))\n",
        "\t# print classification report\n",
        "\tprint('Classification Report:')\n",
        "\tprint(classification_report(actual_labels.numpy(), predicted_labels.numpy()))\n",
        "\n",
        "\treturn predicted_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMbwdpxkyUSB"
      },
      "source": [
        "#### 7. Initialize the Model as ResNet50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialize the model to the number of classes (7), number of epochs (50) and dataloader necessary to train the model with the images that are part of the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6fd2484e1e2143e58177056a3b2a49c9",
            "fe8c044b8d7040e98d022d3ecf5a21d4",
            "a43b595f9b034fc495457ef1df2476f8",
            "8f3a6f19aa1b44b78d4b6b1d9ebe8657",
            "57ab0bad3e70455babf54f889073b508",
            "7a31f9ff2e8f40568f394a55d2df5825",
            "36d70f3e622c48259c501477d0bda0da",
            "cb27a59df46e43418bd0fcd432d83672",
            "dee2f28997484d4e91e44a8c0762a5c4",
            "67bf3fd48f5b4785a691aab9d9fe2e1d",
            "4c923fe75a79402ba90fe3c863e6eced"
          ]
        },
        "id": "W_QevNhaycU-",
        "outputId": "6f921f47-fba7-4be8-d26b-d68bdb08ad3d"
      },
      "outputs": [],
      "source": [
        "model = init_model(num_classes, 50, finetune_all_parmas,\n",
        "\t\t\t\t\tclass_to_idx=datasets_dict['train'].class_to_idx)\n",
        "\n",
        "# transfer model to gpu if available\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf44s5i7yoOB"
      },
      "source": [
        "#### 8. Set Parameters that to be Optimized/Updated\n",
        "We are optimizing both the dense classification layers and the ResNet convolutional base. We are using 50 epochs with a learning rate of 0.0005 and Adam as our chosen optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2t50EQqy1aV"
      },
      "outputs": [],
      "source": [
        "# set parameters needed to be optimized/updated\n",
        "# either entire model parameters or just of last added layer(s)\n",
        "params_to_update = None\n",
        "if not finetune_all_parmas:\n",
        "\tparams_to_update = [param for param in model.parameters() if param.requires_grad]\n",
        "else:\n",
        "\tparams_to_update = model.parameters()\n",
        "\n",
        "\n",
        "num_epochs = 50\n",
        "learning_rate = 0.0005\n",
        "\n",
        "\n",
        "# set optimizer\n",
        "optimizer = torch.optim.Adam(params_to_update, lr=learning_rate)\n",
        "\n",
        "# set loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAiM9DCqzZ4m"
      },
      "source": [
        "#### 9. Call to Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Call the model to be trained with the above set parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "_qZGfB70zePD",
        "outputId": "803b5fbc-2ee9-4f19-eeb6-ca16daae43bf"
      },
      "outputs": [],
      "source": [
        "# train model but do not save\n",
        "trained_model = train(model, dataloaders_dict, criterion, optimizer,\n",
        "\t\tnum_epochs, save_path=None, save_history_to_csv=None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE8pkA84z8Hm"
      },
      "source": [
        "#### 10. Call to Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhONSIOk0Ckw"
      },
      "outputs": [],
      "source": [
        "# test model\n",
        "test(trained_model, dataloaders_dict['test'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The results obtained from training the model with 10% of the KDEF dataset is as plotted below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align=\"center\">\n",
        "<img src=\"https://git.cs.vt.edu/sdeepti/facial-expression-recognition/-/raw/main/Images/dataset_size_graph_small.png\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The results that we found were quite impressive given that the amount of data the model was trained with was significantly less. The graph above shows the upward trend in accuracy the dataset size used for training increases. There is roughly a 10% decrease in accuracy from using 80% of the dataset to only 10% of the dataset. **This shows that our model to could perform well even if it was not trained with a large dataset.**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "train_classifier_different_size.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36d70f3e622c48259c501477d0bda0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c923fe75a79402ba90fe3c863e6eced": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57ab0bad3e70455babf54f889073b508": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67bf3fd48f5b4785a691aab9d9fe2e1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fd2484e1e2143e58177056a3b2a49c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe8c044b8d7040e98d022d3ecf5a21d4",
              "IPY_MODEL_a43b595f9b034fc495457ef1df2476f8",
              "IPY_MODEL_8f3a6f19aa1b44b78d4b6b1d9ebe8657"
            ],
            "layout": "IPY_MODEL_57ab0bad3e70455babf54f889073b508"
          }
        },
        "7a31f9ff2e8f40568f394a55d2df5825": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f3a6f19aa1b44b78d4b6b1d9ebe8657": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67bf3fd48f5b4785a691aab9d9fe2e1d",
            "placeholder": "​",
            "style": "IPY_MODEL_4c923fe75a79402ba90fe3c863e6eced",
            "value": " 97.8M/97.8M [00:01&lt;00:00, 46.5MB/s]"
          }
        },
        "a43b595f9b034fc495457ef1df2476f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb27a59df46e43418bd0fcd432d83672",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dee2f28997484d4e91e44a8c0762a5c4",
            "value": 102530333
          }
        },
        "cb27a59df46e43418bd0fcd432d83672": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dee2f28997484d4e91e44a8c0762a5c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe8c044b8d7040e98d022d3ecf5a21d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a31f9ff2e8f40568f394a55d2df5825",
            "placeholder": "​",
            "style": "IPY_MODEL_36d70f3e622c48259c501477d0bda0da",
            "value": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
