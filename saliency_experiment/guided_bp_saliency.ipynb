{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Backpropagation Saliency Map "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Link to Readme section:    \n",
    "\n",
    "https://git.cs.vt.edu/sdeepti/facial-expression-recognition/-/blob/main/README.md#saliency-maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Citations:\n",
    "\n",
    "- https://github.com/utkuozbulak/pytorch-cnn-visualizations#gradient-visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation:**Â One of the best ways to interpret and visualize the CNN model is through saliency maps. Saliency maps are a way to measure the spatial support of a particular class in each image. It is a visualization technique to gain better insight into the decision-making of the CNN and helps to highlight what each layer of a convolutional layer focuses on.\n",
    "\n",
    "Since the model's interpretability was not as clear using Vanilla Backpropagation (it was a very noisy image), we decided to use another approach which was Guided-Backpropagation Saliency. Guided Backpropagation Saliency combines the previously used Vanilla Backpropagation technique at ReLUs with DeconvNets. Guided backpropagation visualizes gradients with respect to the image where negative gradients are suppressed when backpropagating through ReLU layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Initial Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This adds all the imports that are necessary for the code to run smoothly. It involves importing 'torch' which is necessary to work with our model and retrieve our datasets. Additionally, 'matplotlib.cm' is imported to utilize the 'mpl_color_map' feature so that we can use colormaps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.cm as mpl_color_map\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import torch\n",
    "from torch.nn import ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Write the GuidedBackprop class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is a class called GuidedBackProp which produces gradients generated with guided back propagation from the given image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuidedBackprop():\n",
    "\t\"\"\"\n",
    "\t   Produces gradients generated with guided back propagation from the given image\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, model):\n",
    "\t\tself.model = model\n",
    "\t\tself.gradients = None\n",
    "\t\tself.forward_relu_outputs = []\n",
    "\n",
    "\t\t# Put model in evaluation mode\n",
    "\t\tself.model.eval()\n",
    "\t\tself.update_relus()\n",
    "\t\tself.hook_layers()\n",
    "\n",
    "\tdef hook_layers(self):\n",
    "\t\tdef hook_function(module, grad_in, grad_out):\n",
    "\t\t\tself.gradients = grad_in[0]\n",
    "\t\t# Register hook to the first layer\n",
    "\t\tfirst_layer = list(self.model.children())[0]\n",
    "\t\tfirst_layer.register_backward_hook(hook_function)\n",
    "\n",
    "\tdef update_relus(self):\n",
    "\t\t\"\"\"\n",
    "\t\t\tUpdates relu activation functions so that it only returns positive gradients\n",
    "\t\t\"\"\"\n",
    "\t\tdef relu_hook_function(module, grad_in, grad_out):\n",
    "\t\t\t\"\"\"\n",
    "\t\t\tIf there is a negative gradient, changes it to zero\n",
    "\t\t\t\"\"\"\n",
    "\t\t\tif isinstance(module, ReLU):\n",
    "\t\t\t\treturn (torch.clamp(grad_in[0], min=0.0),)\n",
    "\n",
    "\t\t# Loop through layers, hook up ReLUs with relu_hook_function\n",
    "\t\tfor module in self.model.modules():\n",
    "\t\t\tif isinstance(module, ReLU):\n",
    "\t\t\t\tmodule.register_backward_hook(relu_hook_function)\n",
    "\n",
    "\tdef generate_gradients(self, input_image, target_class):\n",
    "\t\t# Forward pass\n",
    "\t\tmodel_output = self.model(input_image)\n",
    "\n",
    "\t\t# Zero gradients\n",
    "\t\tself.model.zero_grad()\n",
    "\n",
    "\t\t# Target for backprop\n",
    "\t\tone_hot_output = torch.FloatTensor(1, model_output.size()[-1]).zero_()\n",
    "\t\tone_hot_output[0][target_class] = 1\n",
    "\n",
    "\t\t# Backward pass\n",
    "\t\tmodel_output.backward(gradient=one_hot_output)\n",
    "\n",
    "\t\t# Convert Pytorch variable to numpy array\n",
    "\t\t# [0] to get rid of the first channel (1,3,224,224)\n",
    "\t\tgradients_as_arr = self.gradients.data.numpy()[0]\n",
    "\t\treturn gradients_as_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Perform Guided Backpropagation on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below calls the GuidedBackprop class that we created, and passes the model to it. Then we retrieve the model's output after passing image. Backpropagation is then done to get the derivative of the output based on the image. The colored gradients are saved before converting them to grayscale, and the resulting grayscale gradients are saved. The positive and negative saliency maps are then plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guided backprop\n",
    "target_example = 0\n",
    "(original_image, prep_img, target_class, file_name_to_export, pretrained_model) =\\\n",
    "  get_params(target_example, model)\n",
    "\n",
    "GBP = GuidedBackprop(model)\n",
    "\n",
    "# Get gradients\n",
    "# Retrieve output from the image\n",
    "output = model(image)\n",
    "\n",
    "# # Do backpropagation to get the derivative of the output based on the image\n",
    "guided_grads = GBP.generate_gradients(prep_img, target_class)\n",
    "\n",
    "# Save colored gradients\n",
    "save_gradient_images(guided_grads, file_name_to_export + '_Guided_BP_color')\n",
    "\n",
    "# Convert to grayscale\n",
    "grayscale_guided_grads = convert_to_grayscale(guided_grads)\n",
    "\n",
    "# Save grayscale gradients\n",
    "save_gradient_images(grayscale_guided_grads, file_name_to_export + '_Guided_BP_gray')\n",
    "\n",
    "# Positive and negative saliency maps\n",
    "pos_sal, neg_sal = get_positive_negative_saliency(guided_grads)\n",
    "save_gradient_images(pos_sal, file_name_to_export + '_pos_sal')\n",
    "save_gradient_images(neg_sal, file_name_to_export + '_neg_sal')\n",
    "\n",
    "print('Guided backprop completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Guided Backpropagation Saliency|Colored Guided Backpropagation|Guided Backpropagation Negative Saliency|Guided Backpropagation Positive Saliency|\n",
    "| ------ | ------ | ------ | ------ |\n",
    "| <img src=\"https://git.cs.vt.edu/sdeepti/facial-expression-recognition/-/raw/main/Images/AF01HAHR_Guided_BP_gray.png\"> | <img src=\"https://git.cs.vt.edu/sdeepti/facial-expression-recognition/-/raw/main/Images/AF01HAHR_Guided_BP_color.png\"> | <img src=\"https://git.cs.vt.edu/sdeepti/facial-expression-recognition/-/raw/main/Images/AF01HAHR_neg_sal.png\"> | <img src=\"https://git.cs.vt.edu/sdeepti/facial-expression-recognition/-/raw/main/Images/AF01HAHR_pos_sal.png\"> |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0cb4e4f248904f6ecbffe6d340b9c348da43b8aab1180ec492e6a4786161b0f7"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
