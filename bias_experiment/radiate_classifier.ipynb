{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Link to Readme section: \n",
    "\n",
    "[Exploring Bias](https://gitlab.cs.vt.edu/sdeepti/facial-expression-recognition/-/blob/main/README.md#exploring-bias-in-our-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Citations:\n",
    "- https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html\n",
    "- https://www.sciencedirect.com/science/article/pii/S0165178117321893"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation:** A prominent issue in the facial recognition domain is that most datasets severely lack diversity. This is especially true regarding race. The lack of diversity means that machine learning models trained on these datasets are significantly biased.\n",
    "\n",
    "To explore how biased our classifier was, we designed an experiment, where we first load our original model that was trained on [KDEF](https://www.kdef.se/home/aboutKDEF.html). Then, we evaluate the trained model on the racially diverse [Radiate](https://www.sciencedirect.com/science/article/pii/S0165178117321893) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initial Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like other experiments, we import the required pytorch classes and functions. We use sklearn for evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets used in experiment\n",
    "- [KDEF](https://www.kdef.se/home/aboutKDEF.html) (Karolinska Directed Emotional Faces) dataset used to train model\n",
    "- [Radiate](https://www.sciencedirect.com/science/article/pii/S0165178117321893) (RAcially DIverse AffecTive Expression) dataset) for evaluating trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant parameters\n",
    "\n",
    "#data_dir = 'face_images_80_10_10'\n",
    "data_dir = 'radiate_faces_80_10_10'\n",
    "print(f'using {data_dir} as data folder')\n",
    "\n",
    "model_save_path = 'FEC_bias' + data_dir + '.pt'\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the trained model on KDEF (not diverse) images\n",
    "\n",
    "Transfer the model to a GPU if avaliable, and then set the model to evaluation mode to imporove performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "model = models.resnet50(num_classes=num_classes)\n",
    "model.load_state_dict(torch.load(model_save_path, map_location='cpu'))\n",
    "# transfer model to gpu if available\n",
    "model = model.to(device)\n",
    "# set model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Radiate Images\n",
    "\n",
    "We load the radiate images to use as the test set. \n",
    "\n",
    "We apply the same preprocessing steps to the Radiate test images. Notably resizing and normalizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformations to apply to test images\n",
    "# data augmentation and normalization for training\n",
    "# just normalization for validation and testing\n",
    "# https://pytorch.org/vision/stable/transforms.html\n",
    "test_transforms = transforms.Compose([\n",
    "\ttransforms.Resize(size=(224, 224)),\n",
    "\ttransforms.ToTensor(),\n",
    "\t# use ImageNet standard mean and std dev for transfer learning\n",
    "\ttransforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "batch_size = 16\n",
    "# create test_set\n",
    "test_set = ImageFolder(os.path.join(data_dir, 'test'))\n",
    "\n",
    "# create tese_loader\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Test Images\n",
    "\n",
    "We record the predictions our model makes on the test set, and then compute evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests performance on test set and computes metrics\n",
    "def test(model, test_loader):\n",
    "\t# list of predicted labels of all batches\n",
    "\tpredicted_labels = torch.zeros(0, dtype=torch.long, device='cpu')\n",
    "\t# list of actual labels of all batches\n",
    "\tactual_labels = torch.zeros(0, dtype=torch.long, device='cpu')\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tmodel.eval()\n",
    "\t\t# get batch of inputs (image) and outputs (expression label) from test_loader\n",
    "\t\tfor inputs, labels in test_loader:\n",
    "\t\t\tinputs = inputs.to(device)\n",
    "\t\t\tlabels = labels.to(device)\n",
    "\n",
    "\t\t\t# use model to predict label\n",
    "\t\t\toutputs = model(inputs)\n",
    "\t\t\t_, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "\t\t\t# append batch prediction labels and actual labels\n",
    "\t\t\tpredicted_labels = torch.cat([predicted_labels, preds.view(-1).cpu()])\n",
    "\t\t\tactual_labels = torch.cat([actual_labels, labels.view(-1).cpu()])\n",
    "\n",
    "\tprint('\\nTest Metrics:')\n",
    "\t# print confusion matrix\n",
    "\tprint('Confusion Matrix:')\n",
    "\tprint(confusion_matrix(actual_labels.numpy(), predicted_labels.numpy()))\n",
    "\n",
    "\tprint('Test Accuracy:', accuracy_score(actual_labels.numpy(), predicted_labels.numpy()))\n",
    "\tprint('F1 score:', f1_score(actual_labels.numpy(), predicted_labels.numpy(), average='weighted'))\n",
    "\t# print classification report\n",
    "\tprint('Classification Report:')\n",
    "\tprint(classification_report(actual_labels.numpy(), predicted_labels.numpy()))\n",
    "\n",
    "\treturn predicted_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load model\n",
    "model = models.resnet50(num_classes=num_classes)\n",
    "model.load_state_dict(torch.load('dataset_size_experiment/dataset_size_70/FEC_resnet50_trained_face_images_70_10_20.pt'))\n",
    "model.eval()\n",
    "\n",
    "# transfer model to gpu if available\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "# test model on radiate images\n",
    "test(model, dataloaders_dict['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Load Test Dataset and Create Dataloader\n",
    "\n",
    "Now we load our test dataset to which we applied transformations, as well as our Gaussian Noise. Then we create the dataloader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset and create dataloader\n",
    "batch_size = 16\n",
    "test_set = datasets.ImageFolder(os.path.join(data_dir, 'test'), transform=test_transforms)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Test Model Performance on Test Set and Compute Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below evaluates our model's performance on the test set with Gaussian Noise added to it (i.e. variance) and computes the metrics we decided to use for all experiments, and prints them. The metrics we are using include a Confusion Matrix, F1 Score, and Classification Report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests performance on test set and computes metrics\n",
    "def test(model, test_loader):\n",
    "\t# list of predicted labels of all batches\n",
    "\tpredicted_labels = torch.zeros(0, dtype=torch.long, device='cpu')\n",
    "\t# list of actual labels of all batches\n",
    "\tactual_labels = torch.zeros(0, dtype=torch.long, device='cpu')\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tmodel.eval()\n",
    "\t\t# get batch of inputs (image) and outputs (expression label) from test_loader\n",
    "\t\tfor inputs, labels in test_loader:\n",
    "\t\t\tinputs = inputs.to(device)\n",
    "\t\t\tlabels = labels.to(device)\n",
    "\n",
    "\t\t\t# use model to predict label\n",
    "\t\t\toutputs = model(inputs)\n",
    "\t\t\t_, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "\t\t\t# append batch prediction labels and actual labels\n",
    "\t\t\tpredicted_labels = torch.cat([predicted_labels, preds.view(-1).cpu()])\n",
    "\t\t\tactual_labels = torch.cat([actual_labels, labels.view(-1).cpu()])\n",
    "\n",
    "\tprint('\\nTest Metrics:')\n",
    "\t# print confusion matrix\n",
    "\tprint('Confusion Matrix:')\n",
    "\tprint(confusion_matrix(actual_labels.numpy(), predicted_labels.numpy()))\n",
    "\n",
    "\tprint('Test Accuracy:', accuracy_score(actual_labels.numpy(), predicted_labels.numpy()))\n",
    "\tprint('F1 score:', f1_score(actual_labels.numpy(), predicted_labels.numpy(), average='weighted'))\n",
    "\t# print classification report\n",
    "\tprint('Classification Report:')\n",
    "\tprint(classification_report(actual_labels.numpy(), predicted_labels.numpy()))\n",
    "\n",
    "\treturn predicted_labels\n",
    "\n",
    "# test model on radiate images\n",
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://git.cs.vt.edu/sdeepti/facial-expression-recognition/-/raw/main/Images/bias-results.png\">"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0cb4e4f248904f6ecbffe6d340b9c348da43b8aab1180ec492e6a4786161b0f7"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
